## データ指向アプリケーションデザイン 10章

### 概要
大容量のデータが処理する場合のバッチ処理について

主に、メモリに乗らないようなデータをどのように加工するかが焦点


### 気になったことメモ・個人的まとめ
- Unix の哲学
  - しばしば耳にするが、具体的に何なのか見たことなかった
    - [wiki](https://ja.wikipedia.org/wiki/UNIX%E5%93%B2%E5%AD%A6)に色々書かれている
    - 普段 Unix 系を触ることは多いので一度はちゃんと読んでおいたほうがよさそう
  - Linux の sort はメモリサイズよりも大きいサイズのデータについて、複数コア用いて処理を行えるのでかなり優秀という話
    - 普段 Python でデータ処理をしていると、メモリに乗らなくて困ることは実際にしばしばある
  - 複数のシステムの資源を活用することはスコープにでないのでその場合は別の手段が必要
- MapReduce
  - レコードごとに処理が走る mapper とグループ化されたデータについて処理を走らせる reducer の組み合わせで大規模データを複数のノードで並行して処理を進める仕組み
    - 何を mapper にやらせて何を reducer にやらせるかなどで色々工夫ができる
      - ソートマージ結合、ブロードキャストハッシュ結合、パーティション化ハッシュ結合が紹介されている
      - ググると他にも[いろいろある](https://medium.com/@ghoshsiddharth25/apache-spark-join-strategies-deep-dive-26bf7e85db28)
    - 高い並列性を担保する一方で、mapper と reducer にできることに限界はある
  - レプリケーション技術を用いることで耐障害性も持たせることができる
  - 前に調べたときは分散処理のためのプログラミングモデルというぐらいの理解で、何がうれしいのかよくわかってなかったので解像度が上がってよさ
    - とはいえ触ったことはまだないので、どれぐらい使いにくいのかはまだあまり実感ない
- データフローエンジン
  - 処理の一連の流れを1つの workflow とみることで MapReduce の制約を緩めている
    - 各々の処理はオペレータと呼ばれる
  - 最近はこちらが主流
    - Spark など
    - GCP の Dataflow の裏の Apache Beam もこれに類するもの
- sushi principle
  - 明日にでも使ってみたい技術用語
  - 加工前のデータを使うほうがいいよという教え [参考](https://www.datasapiens.co.uk/blog/the-sushi-principle)
  - 実際、加工したことで失われたデータを見たくなることなどがデータ分析をしているとよくある
- HDFS
  - Hadoop で使われている分散ファイルシステム
    - Google File System の再実装らしい
  - [色々書かれている](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html)が、低スペックのノードでも動くよう耐久性が高いのが特徴とのこと
    - Namenode というリーダーがいて、データがブロック単位で分散かつレプリケーションされて配置されいてるみたい
  - リードソロモン符号やイレイジャコーディングという言葉が出てきた
    - [M3のテックチャンネルの動画](https://www.youtube.com/watch?v=q-j1sn0PkRs)を見て雰囲気は把握した
      - なぜうまくいくのかは理解してない（省略されている）が、実装するぐらいなら簡単にできそうと感じた（動画がかなりわかりやすい）
    - HDFS が耐久性が高いゆえんがこの辺りにもありそう
